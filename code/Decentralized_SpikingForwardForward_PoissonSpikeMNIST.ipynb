{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This Notebook aims to experiment with the ***decentralized feature*** of the SFF algorithm: the SFF algorithm allows multiple computing nodes that do not communicate with each other to train the same neural network in parallel. This feature is essentially a direct result of the SFF algorithm not using backpropagation.\n",
        "\n",
        "\n",
        "## **Experimental rules**:\n",
        "Create two identical neural networks (same data set, number of layers, number of neurons). After training the neural networks \"alice\" (only the second layer) and \"alice2\" (only the first layer) independently, build a third neural network \"alice3\", which directly references the first layer of \"alice2\" and the second layer of \"alice\".\n",
        "\n",
        "\n",
        "Since \"alice\" and \"alice2\" do not have any communication during the training process, and are only referenced by \"alice3\" at the end, this experiment can be approximated as two computing nodes training the same neural network in parallel, and finally combining result.\n",
        "\n",
        "\n",
        "## **Code implementation:**\n",
        "The first section is responsible for training the second layer of \"alice\" and showing the ***test error*** using only the first layer\n",
        "(***0.92***, to prove that the first layer is not trained. If the second layer is also added to the test at this time, the error will be ***0.47*** - meaning that the second layer has been trained.).\n",
        "\n",
        "On the other hand, the second section is responsible for training the first layer of \"alice2\" and presenting the ***combined test error*** of the first layer (from \"alice2\") and second layer (from \"alice\") of \"alice3\". The result is ***0.12***."
      ],
      "metadata": {
        "id": "80aJfulxFi8F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpa2QJ0RAIj9",
        "outputId": "9715c345-7550-46ed-b5d7-e450cdb4ee6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spikingjelly\n",
            "  Downloading spikingjelly-0.0.0.0.14-py3-none-any.whl (437 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/437.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/437.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m430.1/437.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.6/437.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (2.0.1+cu118)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (1.23.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (4.66.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (0.15.2+cu118)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (1.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->spikingjelly) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->spikingjelly) (16.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->spikingjelly) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->spikingjelly) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->spikingjelly) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->spikingjelly) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->spikingjelly) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->spikingjelly) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->spikingjelly) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->spikingjelly) (1.3.0)\n",
            "Installing collected packages: spikingjelly\n",
            "Successfully installed spikingjelly-0.0.0.0.14\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 94470285.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 34600312.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 32610900.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3260960.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Epoch: 0\n",
            "training layer 0 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/120 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training layer 1 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [02:46<00:00,  1.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test error: 0.9199999962002039\n"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install spikingjelly\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import spikingjelly\n",
        "import torchvision\n",
        "import torch.utils.data as data\n",
        "from tqdm import tqdm\n",
        "from spikingjelly.activation_based import neuron, layer, learning, surrogate, encoding, functional\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "transform2 = Compose([\n",
        "    ToTensor(),\n",
        "    #Normalize((0.1307,), (0.3081,)),\n",
        "    Lambda(lambda x: torch.flatten(x))])\n",
        "data_dir = './data'\n",
        "device = 'cuda:0'\n",
        "b = 500\n",
        "j = 2\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root=data_dir,\n",
        "    train=True,\n",
        "    transform=transform2,\n",
        "    download=True\n",
        ")\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root=data_dir,\n",
        "    train=False,\n",
        "    transform=transform2,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "train_data_loader = data.DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=b,\n",
        "    shuffle=True,\n",
        "    drop_last=False,\n",
        "    num_workers=j,\n",
        "    pin_memory=True\n",
        ")\n",
        "test_data_loader = data.DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=b,\n",
        "    shuffle=True,\n",
        "    drop_last=False,\n",
        "    num_workers=j,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "class LayerOfLain():\n",
        "  def __init__(self, N_input, N_output, pre_time_au = 2.,\n",
        "               post_time_au = 100., time_step = 50,\n",
        "               batch_size = 500, learning_rate = 0.0003, threshold_both = 0.05):\n",
        "    self.single_net = nn.Sequential(\n",
        "        layer.Linear(N_input, N_output, bias=False),\n",
        "        neuron.IFNode(surrogate_function=surrogate.ATan())\n",
        "    ).to(device)\n",
        "    self.threshold_pos = threshold_both\n",
        "    self.threshold_neg = threshold_both\n",
        "    self.min_weight = -1.\n",
        "    self.max_weight = 1.\n",
        "    self.encoder = encoding.PoissonEncoder()\n",
        "    self.time_step = time_step\n",
        "    self.learning_rate = learning_rate\n",
        "    self.pre_time_au = pre_time_au\n",
        "    self.post_time_au = post_time_au\n",
        "    self.batch_size = batch_size\n",
        "    self.N_output = N_output\n",
        "    self.encoder = encoding.PoissonEncoder()\n",
        "    self.learner = learning.MSTDPLearner(step_mode='s', batch_size=self.batch_size,\n",
        "                     synapse=self.single_net[0], sn=self.single_net[1],\n",
        "                     tau_pre=self.pre_time_au, tau_post=self.post_time_au,\n",
        "                     )\n",
        "    self.learner.disable()\n",
        "\n",
        "  def goodness_cal(self, output):\n",
        "    goodness = output.pow(2).mean(1)\n",
        "    #print(goodness)\n",
        "    return goodness\n",
        "\n",
        "  def reward_from_goodness(self, output, pos_flag):\n",
        "    alpha_pos = 1.\n",
        "    alpha_neg = 1.\n",
        "    goodness = output.pow(2).mean(1)\n",
        "    if(pos_flag==True):\n",
        "      return alpha_pos * (goodness - self.threshold_pos)\n",
        "    else:\n",
        "      return alpha_neg * (self.threshold_neg - goodness)\n",
        "\n",
        "\n",
        "  def forward_with_training(self, input_pos, input_neg, insight_pos, insight_neg, stdpflag = True):\n",
        "\n",
        "    weight_opter_stdp = torch.optim.SGD(self.single_net.parameters(), lr=0.01, momentum=0.)\n",
        "    weight_opter_surrogate = torch.optim.Adam(self.single_net.parameters(), lr=self.learning_rate)\n",
        "    if(stdpflag == True):\n",
        "      with torch.no_grad():\n",
        "          self.learner.enable()\n",
        "          reward_pos = 0.\n",
        "          for t in range(self.time_step):\n",
        "              # Positive update\n",
        "              reward_pos = self.reward_from_goodness(self.single_net(input_pos[t]), True)\n",
        "\n",
        "              weight_opter_stdp.zero_grad()\n",
        "              self.learner.step(reward_pos, on_grad=True)\n",
        "              weight_opter_stdp.step()\n",
        "          self.learner.reset()\n",
        "\n",
        "          reward_neg = 0.\n",
        "          for t3 in range(self.time_step):\n",
        "              # Negative update\n",
        "              reward_neg = self.reward_from_goodness(self.single_net(input_neg[t3]), False)\n",
        "\n",
        "              weight_opter_stdp.zero_grad()\n",
        "              self.learner.step(reward_neg, on_grad=True)\n",
        "              weight_opter_stdp.step()\n",
        "          self.learner.reset()\n",
        "          torch.cuda.empty_cache()\n",
        "          self.learner.disable()\n",
        "      functional.reset_net(self.single_net)\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "    goodness_pos = 0.\n",
        "    for t in range(self.time_step):\n",
        "        # Positive update\n",
        "        #print(input_pos.max())\n",
        "        goodness_pos += self.goodness_cal(self.single_net(input_pos[t]))\n",
        "\n",
        "    goodness_pos = goodness_pos / self.time_step\n",
        "\n",
        "    goodness_neg = 0.\n",
        "    for t3 in range(self.time_step):\n",
        "        # Negative update\n",
        "        goodness_neg += self.goodness_cal(self.single_net(input_neg[t3]))\n",
        "\n",
        "    goodness_neg = goodness_neg / self.time_step\n",
        "\n",
        "    combined_pos = self.threshold_pos - goodness_pos - insight_pos\n",
        "    combined_neg = - self.threshold_neg + goodness_neg - insight_neg\n",
        "\n",
        "    loss_mixed = torch.log(torch.exp(torch.cat([combined_pos, combined_neg])) + 1).mean()\n",
        "    weight_opter_surrogate.zero_grad()\n",
        "    loss_mixed.backward()\n",
        "    weight_opter_surrogate.step()\n",
        "    functional.reset_net(self.single_net)\n",
        "\n",
        "  def forward_withOUT_training(self, input_pos, input_neg):\n",
        "    total_output_pos_list = []\n",
        "    total_output_neg_list = []\n",
        "    for t2 in range(self.time_step):\n",
        "      total_output_pos_list.append((self.single_net(input_pos[t2])).detach())\n",
        "      total_output_neg_list.append((self.single_net(input_neg[t2])).detach())\n",
        "\n",
        "    total_output_pos = torch.stack(total_output_pos_list, dim=0)\n",
        "    total_output_neg = torch.stack(total_output_neg_list, dim=0)\n",
        "    return total_output_pos, total_output_neg\n",
        "\n",
        "  def forward_withOUT_training_single(self, input_pos, firstflag):\n",
        "    total_output_pos_list = []\n",
        "    if(firstflag==0):\n",
        "      for t2 in range(self.time_step):\n",
        "        total_output_pos_list.append(self.single_net(input_pos[t2]).detach())\n",
        "      total_output_pos = torch.stack(total_output_pos_list, dim=0)\n",
        "    else:\n",
        "      for t2 in range(self.time_step):\n",
        "        total_output_pos_list.append(self.single_net(input_pos[t2]).detach())\n",
        "      total_output_pos = torch.stack(total_output_pos_list, dim=0)\n",
        "\n",
        "\n",
        "    return total_output_pos\n",
        "\n",
        "def label_encoder(input, label):\n",
        "    labeled_input = input.clone()\n",
        "    labeled_input[:, :10] *= 0.0\n",
        "    labeled_input[range(input.shape[0]), label] = 1.0\n",
        "    labeled_input[:, -28:-18] *= 0.0\n",
        "    labeled_input[range(input.shape[0]), -28+label] = 1.0\n",
        "    return labeled_input\n",
        "\n",
        "def poisson_iter(input, t):\n",
        "    batch_size, dim = input.shape\n",
        "    output = torch.zeros((t, batch_size, dim))\n",
        "    encoder = encoding.PoissonEncoder()\n",
        "    for i in range(t):\n",
        "        encoden_input = encoder(input)\n",
        "        output[i] = encoden_input\n",
        "    return output\n",
        "\n",
        "class NetOfLain(torch.nn.Module):\n",
        "    def __init__(self, lain_dimension):\n",
        "        super().__init__()\n",
        "        self.lain_layers = []\n",
        "        self.insight_pos = 0.\n",
        "        self.insight_neg = 0.\n",
        "        for d in range(len(lain_dimension) - 1):\n",
        "            if(d == 0):\n",
        "              layer = LayerOfLain(lain_dimension[d], lain_dimension[d + 1], pre_time_au = 2., post_time_au = 100.)\n",
        "              self.lain_layers.append(layer)\n",
        "            else:\n",
        "              layer = LayerOfLain(lain_dimension[d], lain_dimension[d + 1], pre_time_au = 2., post_time_au = 100., learning_rate = 0.004, threshold_both=0.04)\n",
        "              self.lain_layers.append(layer)\n",
        "\n",
        "    def network_train_layers(self, train_data_loader, epo):\n",
        "      torch.cuda.empty_cache()\n",
        "      for i, lain_layer in enumerate(self.lain_layers):\n",
        "        print('training layer', i, '...')\n",
        "        for features, labels in tqdm(train_data_loader):\n",
        "          if(i==0):\n",
        "            break;\n",
        "          torch.cuda.empty_cache()\n",
        "          features, labels = features.to(device), labels.to(device)\n",
        "          features_pos = label_encoder(features, labels)\n",
        "          rnd = torch.randperm(features.size(0))\n",
        "          features_neg = label_encoder(features, labels[rnd])\n",
        "          features_pos = poisson_iter(features_pos, lain_layer.time_step)\n",
        "          features_pos = features_pos.to(device)\n",
        "          features_neg = poisson_iter(features_neg, lain_layer.time_step)\n",
        "          features_neg = features_neg.to(device)\n",
        "          del features, labels\n",
        "          torch.cuda.empty_cache()\n",
        "          #features_pos = features_pos.transpose(0, 1)\n",
        "          #features_neg = features_neg.transpose(0, 1)\n",
        "          self.insight_pos = self.network_collaboration(features_pos)\n",
        "          self.insight_neg = self.network_collaboration(features_neg)\n",
        "          positive_hidden, negative_hidden = features_pos, features_neg\n",
        "          if(i > 0) :\n",
        "            for o in range(i):\n",
        "              positive_hidden, negative_hidden = self.lain_layers[o].forward_withOUT_training(positive_hidden, negative_hidden)\n",
        "              functional.reset_net(self.lain_layers[o].single_net)\n",
        "          torch.cuda.empty_cache()\n",
        "          if(i==0):\n",
        "            lain_layer.forward_with_training(positive_hidden, negative_hidden, self.insight_pos, self.insight_neg, stdpflag=False)\n",
        "          else:\n",
        "            lain_layer.forward_with_training(positive_hidden, negative_hidden, self.insight_pos, self.insight_neg, stdpflag=True)\n",
        "\n",
        "    def network_predict(self, input):\n",
        "      every_labels_goodness = []\n",
        "      for label in range(10):\n",
        "        hidden = label_encoder(input, label)\n",
        "        hidden = poisson_iter(hidden, 50)\n",
        "        hidden = hidden.to(device)\n",
        "        torch.cuda.empty_cache()\n",
        "        every_layer_goodness = []\n",
        "        for p, lain_layer in enumerate(self.lain_layers):\n",
        "          hidden = lain_layer.forward_withOUT_training_single(hidden, p)\n",
        "          goodnesstem = []\n",
        "          for t in range(lain_layer.time_step):\n",
        "            goodnesstem.append((hidden[t].pow(2).mean(1)).unsqueeze(0))\n",
        "          every_layer_goodness += [(torch.cat(goodnesstem, dim=0)).sum(0)]\n",
        "        every_labels_goodness += [every_layer_goodness[0].unsqueeze(1)]\n",
        "        del hidden\n",
        "        #for lain_layer in self.lain_layers:\n",
        "          #functional.reset_net(lain_layer.single_net)\n",
        "        torch.cuda.empty_cache()\n",
        "      every_labels_goodness = torch.cat(every_labels_goodness, 1)\n",
        "      return every_labels_goodness.argmax(1)\n",
        "\n",
        "    def network_collaboration(self, input):\n",
        "        hidden = input.clone()\n",
        "        every_layer_goodness = []\n",
        "        for p, lain_layer in enumerate(self.lain_layers):\n",
        "          hidden = lain_layer.forward_withOUT_training_single(hidden, p)\n",
        "          goodnesstem = []\n",
        "          for t in range(lain_layer.time_step):\n",
        "            goodnesstem.append((hidden[t].pow(2).mean(1)).unsqueeze(0))\n",
        "          every_layer_goodness += [(torch.cat(goodnesstem, dim=0)).sum(0)]\n",
        "          functional.reset_net(lain_layer.single_net)\n",
        "        del hidden\n",
        "        torch.cuda.empty_cache()\n",
        "        return sum(every_layer_goodness)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    torch.manual_seed(1000)\n",
        "    torch.cuda.empty_cache()\n",
        "    alice = NetOfLain([784, 500, 500])\n",
        "    for epo in range(1):\n",
        "      print(\"Epoch:\", epo)\n",
        "      torch.cuda.empty_cache()\n",
        "      alice.network_train_layers(train_data_loader, epo)\n",
        "      countT = 0.\n",
        "      lossT = 0.\n",
        "      for test_x, test_y in test_data_loader:\n",
        "        test_x, test_y = test_x.to(device), test_y.to(device)\n",
        "        lossT += 1.0 - alice.network_predict(test_x).eq(test_y).float().mean().item()\n",
        "        countT += 1\n",
        "        for lain_layer in alice.lain_layers:\n",
        "          functional.reset_net(lain_layer.single_net)\n",
        "      print('test error:', lossT / countT)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install spikingjelly\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import spikingjelly\n",
        "import torchvision\n",
        "import torch.utils.data as data\n",
        "from tqdm import tqdm\n",
        "from spikingjelly.activation_based import neuron, layer, learning, surrogate, encoding, functional\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "transform2 = Compose([\n",
        "    ToTensor(),\n",
        "    #Normalize((0.1307,), (0.3081,)),\n",
        "    Lambda(lambda x: torch.flatten(x))])\n",
        "data_dir = './data'\n",
        "device = 'cuda:0'\n",
        "b = 500\n",
        "j = 2\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root=data_dir,\n",
        "    train=True,\n",
        "    transform=transform2,\n",
        "    download=True\n",
        ")\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root=data_dir,\n",
        "    train=False,\n",
        "    transform=transform2,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "train_data_loader = data.DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=b,\n",
        "    shuffle=True,\n",
        "    drop_last=False,\n",
        "    num_workers=j,\n",
        "    pin_memory=True\n",
        ")\n",
        "test_data_loader = data.DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=b,\n",
        "    shuffle=True,\n",
        "    drop_last=False,\n",
        "    num_workers=j,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "class LayerOfLain():\n",
        "  def __init__(self, N_input, N_output, pre_time_au = 2.,\n",
        "               post_time_au = 100., time_step = 50,\n",
        "               batch_size = 500, learning_rate = 0.0003, threshold_both = 0.05):\n",
        "    self.single_net = nn.Sequential(\n",
        "        layer.Linear(N_input, N_output, bias=False),\n",
        "        neuron.IFNode(surrogate_function=surrogate.ATan())\n",
        "    ).to(device)\n",
        "    self.threshold_pos = threshold_both\n",
        "    self.threshold_neg = threshold_both\n",
        "    self.min_weight = -1.\n",
        "    self.max_weight = 1.\n",
        "    self.encoder = encoding.PoissonEncoder()\n",
        "    self.time_step = time_step\n",
        "    self.learning_rate = learning_rate\n",
        "    self.pre_time_au = pre_time_au\n",
        "    self.post_time_au = post_time_au\n",
        "    self.batch_size = batch_size\n",
        "    self.N_output = N_output\n",
        "    self.encoder = encoding.PoissonEncoder()\n",
        "    self.learner = learning.MSTDPLearner(step_mode='s', batch_size=self.batch_size,\n",
        "                     synapse=self.single_net[0], sn=self.single_net[1],\n",
        "                     tau_pre=self.pre_time_au, tau_post=self.post_time_au,\n",
        "                     )\n",
        "    self.learner.disable()\n",
        "\n",
        "  def goodness_cal(self, output):\n",
        "    goodness = output.pow(2).mean(1)\n",
        "    #print(goodness)\n",
        "    return goodness\n",
        "\n",
        "  def reward_from_goodness(self, output, pos_flag):\n",
        "    alpha_pos = 1.\n",
        "    alpha_neg = 1.\n",
        "    goodness = output.pow(2).mean(1)\n",
        "    if(pos_flag==True):\n",
        "      return alpha_pos * (goodness - self.threshold_pos)\n",
        "    else:\n",
        "      return alpha_neg * (self.threshold_neg - goodness)\n",
        "\n",
        "\n",
        "  def forward_with_training(self, input_pos, input_neg, insight_pos, insight_neg, stdpflag = True):\n",
        "\n",
        "    weight_opter_stdp = torch.optim.SGD(self.single_net.parameters(), lr=0.01, momentum=0.)\n",
        "    weight_opter_surrogate = torch.optim.Adam(self.single_net.parameters(), lr=self.learning_rate)\n",
        "    if(stdpflag == True):\n",
        "      with torch.no_grad():\n",
        "          self.learner.enable()\n",
        "          reward_pos = 0.\n",
        "          for t in range(self.time_step):\n",
        "              # Positive update\n",
        "              reward_pos = self.reward_from_goodness(self.single_net(input_pos[t]), True)\n",
        "\n",
        "              weight_opter_stdp.zero_grad()\n",
        "              self.learner.step(reward_pos, on_grad=True)\n",
        "              weight_opter_stdp.step()\n",
        "          self.learner.reset()\n",
        "\n",
        "          reward_neg = 0.\n",
        "          for t3 in range(self.time_step):\n",
        "              # Negative update\n",
        "              reward_neg = self.reward_from_goodness(self.single_net(input_neg[t3]), False)\n",
        "\n",
        "              weight_opter_stdp.zero_grad()\n",
        "              self.learner.step(reward_neg, on_grad=True)\n",
        "              weight_opter_stdp.step()\n",
        "          self.learner.reset()\n",
        "          torch.cuda.empty_cache()\n",
        "          self.learner.disable()\n",
        "      functional.reset_net(self.single_net)\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "    goodness_pos = 0.\n",
        "    for t in range(self.time_step):\n",
        "        # Positive update\n",
        "        #print(input_pos.max())\n",
        "        goodness_pos += self.goodness_cal(self.single_net(input_pos[t]))\n",
        "\n",
        "    goodness_pos = goodness_pos / self.time_step\n",
        "\n",
        "    goodness_neg = 0.\n",
        "    for t3 in range(self.time_step):\n",
        "        # Negative update\n",
        "        goodness_neg += self.goodness_cal(self.single_net(input_neg[t3]))\n",
        "\n",
        "    goodness_neg = goodness_neg / self.time_step\n",
        "\n",
        "    combined_pos = self.threshold_pos - goodness_pos - insight_pos\n",
        "    combined_neg = - self.threshold_neg + goodness_neg - insight_neg\n",
        "\n",
        "    loss_mixed = torch.log(torch.exp(torch.cat([combined_pos, combined_neg])) + 1).mean()\n",
        "    weight_opter_surrogate.zero_grad()\n",
        "    loss_mixed.backward()\n",
        "    weight_opter_surrogate.step()\n",
        "    functional.reset_net(self.single_net)\n",
        "\n",
        "  def forward_withOUT_training(self, input_pos, input_neg):\n",
        "    total_output_pos_list = []\n",
        "    total_output_neg_list = []\n",
        "    for t2 in range(self.time_step):\n",
        "      total_output_pos_list.append((self.single_net(input_pos[t2])).detach())\n",
        "      total_output_neg_list.append((self.single_net(input_neg[t2])).detach())\n",
        "\n",
        "    total_output_pos = torch.stack(total_output_pos_list, dim=0)\n",
        "    total_output_neg = torch.stack(total_output_neg_list, dim=0)\n",
        "    return total_output_pos, total_output_neg\n",
        "\n",
        "  def forward_withOUT_training_single(self, input_pos, firstflag):\n",
        "    total_output_pos_list = []\n",
        "    if(firstflag==0):\n",
        "      for t2 in range(self.time_step):\n",
        "        total_output_pos_list.append(self.single_net(input_pos[t2]).detach())\n",
        "      total_output_pos = torch.stack(total_output_pos_list, dim=0)\n",
        "    else:\n",
        "      for t2 in range(self.time_step):\n",
        "        total_output_pos_list.append(self.single_net(input_pos[t2]).detach())\n",
        "      total_output_pos = torch.stack(total_output_pos_list, dim=0)\n",
        "\n",
        "\n",
        "    return total_output_pos\n",
        "\n",
        "def label_encoder(input, label):\n",
        "    labeled_input = input.clone()\n",
        "    labeled_input[:, :10] *= 0.0\n",
        "    labeled_input[range(input.shape[0]), label] = 1.0\n",
        "    labeled_input[:, -28:-18] *= 0.0\n",
        "    labeled_input[range(input.shape[0]), -28+label] = 1.0\n",
        "    return labeled_input\n",
        "\n",
        "def poisson_iter(input, t):\n",
        "    batch_size, dim = input.shape\n",
        "    output = torch.zeros((t, batch_size, dim))\n",
        "    encoder = encoding.PoissonEncoder()\n",
        "    for i in range(t):\n",
        "        encoden_input = encoder(input)\n",
        "        output[i] = encoden_input\n",
        "    return output\n",
        "\n",
        "class NetOfLain(torch.nn.Module):\n",
        "    def __init__(self, lain_dimension):\n",
        "        super().__init__()\n",
        "        self.lain_layers = []\n",
        "        self.insight_pos = 0.\n",
        "        self.insight_neg = 0.\n",
        "        for d in range(len(lain_dimension) - 1):\n",
        "            if(d == 0):\n",
        "              layer = LayerOfLain(lain_dimension[d], lain_dimension[d + 1], pre_time_au = 2., post_time_au = 100.)\n",
        "              self.lain_layers.append(layer)\n",
        "            else:\n",
        "              layer = LayerOfLain(lain_dimension[d], lain_dimension[d + 1], pre_time_au = 2., post_time_au = 100., learning_rate = 0.004, threshold_both=0.04)\n",
        "              self.lain_layers.append(layer)\n",
        "\n",
        "    def network_train_layers(self, train_data_loader, epo):\n",
        "      torch.cuda.empty_cache()\n",
        "      for i, lain_layer in enumerate(self.lain_layers):\n",
        "        print('training layer', i, '...')\n",
        "        for features, labels in tqdm(train_data_loader):\n",
        "          if(i>0):\n",
        "            break;\n",
        "          torch.cuda.empty_cache()\n",
        "          features, labels = features.to(device), labels.to(device)\n",
        "          features_pos = label_encoder(features, labels)\n",
        "          rnd = torch.randperm(features.size(0))\n",
        "          features_neg = label_encoder(features, labels[rnd])\n",
        "          features_pos = poisson_iter(features_pos, lain_layer.time_step)\n",
        "          features_pos = features_pos.to(device)\n",
        "          features_neg = poisson_iter(features_neg, lain_layer.time_step)\n",
        "          features_neg = features_neg.to(device)\n",
        "          del features, labels\n",
        "          torch.cuda.empty_cache()\n",
        "          #features_pos = features_pos.transpose(0, 1)\n",
        "          #features_neg = features_neg.transpose(0, 1)\n",
        "          self.insight_pos = self.network_collaboration(features_pos)\n",
        "          self.insight_neg = self.network_collaboration(features_neg)\n",
        "          positive_hidden, negative_hidden = features_pos, features_neg\n",
        "          if(i > 0) :\n",
        "            for o in range(i):\n",
        "              positive_hidden, negative_hidden = self.lain_layers[o].forward_withOUT_training(positive_hidden, negative_hidden)\n",
        "              functional.reset_net(self.lain_layers[o].single_net)\n",
        "          torch.cuda.empty_cache()\n",
        "          if(i==0):\n",
        "            lain_layer.forward_with_training(positive_hidden, negative_hidden, self.insight_pos, self.insight_neg, stdpflag=False)\n",
        "          else:\n",
        "            lain_layer.forward_with_training(positive_hidden, negative_hidden, self.insight_pos, self.insight_neg, stdpflag=True)\n",
        "\n",
        "    def network_predict(self, input):\n",
        "      every_labels_goodness = []\n",
        "      for label in range(10):\n",
        "        hidden = label_encoder(input, label)\n",
        "        hidden = poisson_iter(hidden, 50)\n",
        "        hidden = hidden.to(device)\n",
        "        torch.cuda.empty_cache()\n",
        "        every_layer_goodness = []\n",
        "        for p, lain_layer in enumerate(self.lain_layers):\n",
        "          hidden = lain_layer.forward_withOUT_training_single(hidden, p)\n",
        "          goodnesstem = []\n",
        "          for t in range(lain_layer.time_step):\n",
        "            goodnesstem.append((hidden[t].pow(2).mean(1)).unsqueeze(0))\n",
        "          every_layer_goodness += [(torch.cat(goodnesstem, dim=0)).sum(0)]\n",
        "        every_labels_goodness += [sum(every_layer_goodness).unsqueeze(1)]\n",
        "        del hidden\n",
        "        #for lain_layer in self.lain_layers:\n",
        "          #functional.reset_net(lain_layer.single_net)\n",
        "        torch.cuda.empty_cache()\n",
        "      every_labels_goodness = torch.cat(every_labels_goodness, 1)\n",
        "      return every_labels_goodness.argmax(1)\n",
        "\n",
        "    def network_collaboration(self, input):\n",
        "        hidden = input.clone()\n",
        "        every_layer_goodness = []\n",
        "        for p, lain_layer in enumerate(self.lain_layers):\n",
        "          hidden = lain_layer.forward_withOUT_training_single(hidden, p)\n",
        "          goodnesstem = []\n",
        "          for t in range(lain_layer.time_step):\n",
        "            goodnesstem.append((hidden[t].pow(2).mean(1)).unsqueeze(0))\n",
        "          every_layer_goodness += [(torch.cat(goodnesstem, dim=0)).sum(0)]\n",
        "          functional.reset_net(lain_layer.single_net)\n",
        "        del hidden\n",
        "        torch.cuda.empty_cache()\n",
        "        return sum(every_layer_goodness)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    torch.manual_seed(1000)\n",
        "    torch.cuda.empty_cache()\n",
        "    alice2 = NetOfLain([784, 500, 500])\n",
        "    print(alice2.lain_layers[1].single_net[0].weight.data.max())\n",
        "    alice3 = NetOfLain([784, 500, 500])\n",
        "    alice3.lain_layers[0] = alice2.lain_layers[0]\n",
        "    alice3.lain_layers[1] = alice.lain_layers[1]\n",
        "    for epo in range(1):\n",
        "      print(\"Epoch:\", epo)\n",
        "      torch.cuda.empty_cache()\n",
        "      alice3.network_train_layers(train_data_loader, epo)\n",
        "      countT = 0.\n",
        "      lossT = 0.\n",
        "      for test_x, test_y in test_data_loader:\n",
        "        test_x, test_y = test_x.to(device), test_y.to(device)\n",
        "        lossT += 1.0 - alice3.network_predict(test_x).eq(test_y).float().mean().item()\n",
        "        countT += 1\n",
        "        for lain_layer in alice3.lain_layers:\n",
        "          functional.reset_net(lain_layer.single_net)\n",
        "      print('test error:', lossT / countT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNb7lXIQA8AG",
        "outputId": "0a17e6df-0b26-4dba-97e1-55a2c7980f9e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spikingjelly in /usr/local/lib/python3.10/dist-packages (0.0.0.0.14)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (2.0.1+cu118)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (1.23.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (4.66.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (0.15.2+cu118)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (1.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->spikingjelly) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->spikingjelly) (16.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->spikingjelly) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->spikingjelly) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->spikingjelly) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->spikingjelly) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->spikingjelly) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->spikingjelly) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->spikingjelly) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->spikingjelly) (1.3.0)\n",
            "tensor(0.0447, device='cuda:0')\n",
            "Epoch: 0\n",
            "training layer 0 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [01:01<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training layer 1 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/120 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test error: 0.12019995450973511\n"
          ]
        }
      ]
    }
  ]
}